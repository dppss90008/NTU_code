# install.packages("xml2")
# install.packages("rvest")
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://scweb.cwb.gov.tw/GraphicContent.aspx?ItemId=20&Date=201802&t=23d140a6-96f1-420f-b57f-6eee751cd48b")
txt=html_nodes(txt,"#ContentPlaceHolder1_ctl00_gvEarthquake a , #ContentPlaceHolder1_ctl00_gvEarthquake th")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
earthquake_data <- matrix(txt[8:length(txt)],(nrow=length(txt)-7)/7,ncol=7,byrow= TRUE)
# data processing : clean the data and store it into dataframe type
name <- txt[1:7]
earthquake_data <- data.frame(earthquake_data)
names(earthquake_data) <- name
View(earthquake_data)
# data processing : clean the data and store it into dataframe type
name <- txt[1:7]
name[3] <- 'Lon'
name[4] <- 'Lat'
earthquake_data <- matrix(txt[8:length(txt)],(nrow=length(txt)-7)/7,ncol=7,byrow= TRUE)
earthquake_data <- data.frame(earthquake_data)
names(earthquake_data) <- name
View(earthquake_data)
# Earthquake quake data crawler
# install.packages("xml2")
# install.packages("rvest")
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://scweb.cwb.gov.tw/GraphicContent.aspx?ItemId=20&Date=201802&t=23d140a6-96f1-420f-b57f-6eee751cd48b")
txt=html_nodes(txt,"#ContentPlaceHolder1_ctl00_gvEarthquake a , #ContentPlaceHolder1_ctl00_gvEarthquake th")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
# data processing : clean the data and store it into dataframe type
name <- txt[1:7]
name[3] <- 'Lon'
name[4] <- 'Lat'
earthquake_data <- matrix(txt[8:length(txt)],(nrow=length(txt)-7)/7,ncol=7,byrow= TRUE)
earthquake_data <- data.frame(earthquake_data)
names(earthquake_data) <- name
View(earthquake_data)
# data image : Use google map to image earthquake data
library(ggmap)
lon <- sapply((strsplit(as.character(earthquake_data$Lon), ",")), as.numeric)
lat <- sapply((strsplit(as.character(earthquake_data$Lat), ",")), as.numeric)
map <- get_map(location = 'Taiwan', zoom = 7, maptype = "terrain")
ggmap(map, darken = c(0.5, "white")) + geom_point(aes(x = lon, y = lat),size=2,color = 'dark blue',data = earthquake_data)
install.packages("dplyr")
install.packages("tidyverse")
# Earthquake quake data crawler
# install.packages("xml2")
# install.packages("rvest")
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://scweb.cwb.gov.tw/GraphicContent.aspx?ItemId=20&Date=201802&t=23d140a6-96f1-420f-b57f-6eee751cd48b")
# Earthquake quake data crawler
# install.packages("xml2")
# install.packages("rvest")
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://scweb.cwb.gov.tw/GraphicContent.aspx?ItemId=20&Date=201802&t=23d140a6-96f1-420f-b57f-6eee751cd48b")
txt=html_nodes(txt,"#ContentPlaceHolder1_ctl00_gvEarthquake a , #ContentPlaceHolder1_ctl00_gvEarthquake th")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
# data processing : clean the data and store it into dataframe type
name <- txt[1:7]
name[3] <- 'Lon'
name[4] <- 'Lat'
earthquake_data <- matrix(txt[8:length(txt)],(nrow=length(txt)-7)/7,ncol=7,byrow= TRUE)
earthquake_data <- data.frame(earthquake_data)
names(earthquake_data) <- name
View(earthquake_data)
# data image : Use google map to image earthquake data
library(ggmap)
lon <- sapply((strsplit(as.character(earthquake_data$Lon), ",")), as.numeric)
lat <- sapply((strsplit(as.character(earthquake_data$Lat), ",")), as.numeric)
map <- get_map(location = 'Taiwan', zoom = 7, maptype = "terrain")
ggmap(map, darken = c(0.5, "white")) + geom_point(aes(x = lon, y = lat),size=2,color = 'dark blue',data = earthquake_data)
install.packages("tidyverse")
library(tidyverse)
install.packages("tidyverse")
library(nycflights13)
install.packages("nycflights13")
summary(earthquake_data)
ggplot(data = earthquake_data, aes(x = 深度)) +
geom_bar(fill = "lightblue", colour = "black")
ggplot(data = earthquake_data, aes(x = 規模)) +
geom_bar(fill = "lightblue", colour = "black")
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://scweb.cwb.gov.tw/GraphicContent.aspx?ItemId=20&Date=201802&t=23d140a6-96f1-420f-b57f-6eee751cd48b")
txt=html_nodes(txt,"#ContentPlaceHolder1_ctl00_gvEarthquake a , #ContentPlaceHolder1_ctl00_gvEarthquake th")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
View(txt)
name <- txt[1:7]
name[3] <- 'Lon'
name[4] <- 'Lat'
earthquake_data <- matrix(txt[8:length(txt)],(nrow=length(txt)-7)/7,ncol=7,byrow= TRUE)
earthquake_data <- data.frame(earthquake_data)
names(earthquake_data) <- name
View(earthquake_data)
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,"td")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,"td")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,"tr")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,".top .td , dd , .rank_txt")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
txt
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,".count , .top .td , dd , .rank_txt")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
txt
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,".count , .td , dd , .rank_txt")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
txt
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,".count , .top .td , dd , .rank_txt")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
txt
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,".count , .top .td , dd ")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
txt
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,".icon_notice a , .count , .top .td , dd , .rank_txt")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
txt
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,".icon_notice a , .count , .top .td , #content_l dd , .rank_txt")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
txt
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,"td")
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,".td")
View(txt)
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,".icon_notice a , .count , .top .td , #content_l dd , .rank_txt")
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,".icon_notice a , .count , .top .td , #content_l dd , .rank_txt")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
txt
txt
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,"h1 , .icon_notice a , .count , .top .td , .rank_txt")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
txt
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://movies.yahoo.com.tw/chart.html?cate=rating")
txt=html_nodes(txt,"#content_l h1 , .icon_notice a , .count , .top .td , .rank_txt")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
txt
res <- read_html("https://movies.yahoo.com.tw/chart.html?cate=rating&search_year=2018%22")
movies.names <- html_nodes(res,".ga_ranking , .count , .rank_txt , .td:nth-child(1) , h1")
movies.names <- html_text(movies.names)
movies.names <- iconv(movies.names, "UTF-8")
movies.names
/* data()*/
library(ggplot2)
NBA1516<-fetch_NBAPlayerStatistics("15-16")
library(SportsAnalytics)
install.packages("SportAnalytics")
library(iris)
data <- iris
View(data)
View(data)
iris_data <- iris
library(ggplot2)
iris_data <- iris
qplot(data=iris_data,x=iris_data$Sepal.Length,y=iris_data$Sepal.Width)
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width, xlab = 'XD' )
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width,
xlab = 'Sepal.Length', ylab = 'Sepal.Width' )
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width,
xlab = 'Sepal.Length', ylab = 'Sepal.Width', size = cyl)
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width,
xlab = 'Sepal.Length', ylab = 'Sepal.Width')
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width,
xlab = 'Sepal.Length', ylab = 'Sepal.Width',color = iris_data$Species)
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width,
xlab = 'Sepal.Length', ylab = 'Sepal.Width',color = iris_data$Species, geom = c("point", "smooth"))
qplot(iris_data, data = iris_data, fill = iris_data$Species)
qplot(iris_data$Sepal.Length, data = iris_data, fill = iris_data$Species)
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width,
xlab = 'Sepal.Length', ylab = 'Sepal.Width',color = iris_data$Species,
geom_smooth(method='lm'))
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width,
xlab = 'Sepal.Length', ylab = 'Sepal.Width',color = iris_data$Species,
geom = c("point", "smooth"))
library(ggmap)
twmap <- get_map(location = 'Taiwan', zoom = 7,language = "zh-TW")
ggmap(twmap)
twmap <- get_map(location = 'USA', zoom = 7,language = "zh-TW")
ggmap(twmap)
twmap <- get_map(location = 'USA', zoom = 12,language = "zh-TW")
ggmap(twmap)
twmap <- get_map(location = 'USA', zoom = 4,language = "zh-TW")
ggmap(twmap)
twmap <- get_map(location = 'USA', zoom = 0.1,language = "zh-TW")
ggmap(twmap)
twmap <- get_map(location = 'USA', zoom = 000.1,language = "zh-TW")
twmap <- get_map(location = 'USA', zoom = 21,language = "zh-TW")
ggmap(twmap)
twmap <- get_map(location = 'USA', zoom = 21)
ggmap(twmap)
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width,
xlab = 'Sepal.Length', ylab = 'Sepal.Width',color = iris_data$Species,
geom = c("point", "smooth"))
qplot(iris_data$Sepal.Length, data = iris_data, fill = iris_data$Species)
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width,
xlab = 'Sepal.Length', ylab = 'Sepal.Width',color = iris_data$Species,
geom = c("point", "smooth"))
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://scweb.cwb.gov.tw/GraphicContent.aspx?ItemId=20&Date=201802&t=23d140a6-96f1-420f-b57f-6eee751cd48b")
txt=html_nodes(txt,"#ContentPlaceHolder1_ctl00_gvEarthquake a , #ContentPlaceHolder1_ctl00_gvEarthquake th")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
# data processing : clean the data and store it into dataframe type
name <- txt[1:7]
name[3] <- 'Lon'
name[4] <- 'Lat'
earthquake_data <- matrix(txt[8:length(txt)],(nrow=length(txt)-7)/7,ncol=7,byrow= TRUE)
earthquake_data <- data.frame(earthquake_data)
names(earthquake_data) <- name
write.csv(earthquake_data,file="Earthquake_data.csv")
setwd("~/GitHub/NTU_code/NTU_code/week_2/hw_2")
name <- txt[1:7]
name[3] <- 'Lon'
name[4] <- 'Lat'
earthquake_data <- matrix(txt[8:length(txt)],(nrow=length(txt)-7)/7,ncol=7,byrow= TRUE)
earthquake_data <- data.frame(earthquake_data)
names(earthquake_data) <- name
write.csv(earthquake_data,file="Earthquake_data.csv")
setwd("~/GitHub/NTU_code/NTU_code/week_3/hw3")
dat <- read.csv("Earthquake_data.csv")
dat <- read.csv("Earthquake_data.csv")
View(dat)
library(ggmap)
lon <- sapply((strsplit(as.character(dat$Longitude), ",")), as.numeric)
lat <- sapply((strsplit(as.character(dat$Latitude), ",")), as.numeric)
map <- get_map(location = 'Taiwan', zoom = 7, maptype = "terrain")
ggmap(map, darken = c(0.5, "white")) + geom_point(aes(x = lon, y = lat),size=2,
color = 'dark blue',data = earthquake_data)
map <- get_map(location = 'Taiwan', zoom = 7, maptype = "terrain")
ggmap(map, darken = c(0.5, "white")) + geom_point(aes(x = lon, y = lat),size=2,
color = 'dark blue',data = dat)
library(ggplot2)
iris_data <- iris
# Scatter Diagram
qplot(data=iris_data, x=iris_data$Sepal.Length, y=iris_data$Sepal.Width,
xlab = 'Sepal.Length', ylab = 'Sepal.Width',color = iris_data$Species,
geom = c("point", "smooth"))
qplot(iris_data$Sepal.Length, data = iris_data, fill = iris_data$Species)
#
qplot(x = dat$magnitude)
ggplot(data = dat, aes(x = dat$magnitude) +
geom_bar(fill = "lightblue", colour = "black")
#
ggplot(data = dat, aes(x = magnitude) + geom_bar(fill = "lightblue", colour = "black")
# install.packages("rvest")
library(xml2)
library(rvest)
# Crawling earthquake data from cwb date set : 201802
txt=read_html("https://scweb.cwb.gov.tw/GraphicContent.aspx?ItemId=20&Date=201802&t=23d140a6-96f1-420f-b57f-6eee751cd48b")
txt=html_nodes(txt,"#ContentPlaceHolder1_ctl00_gvEarthquake a , #ContentPlaceHolder1_ctl00_gvEarthquake th")
txt=html_text(txt)
txt=iconv(txt,"UTF-8")
# data processing : clean the data and store it into dataframe type
name <- txt[1:7]
name[3] <- 'Lon'
name[4] <- 'Lat'
earthquake_data <- matrix(txt[8:length(txt)],(nrow=length(txt)-7)/7,ncol=7,byrow= TRUE)
earthquake_data <- data.frame(earthquake_data)
names(earthquake_data) <- name
View(earthquake_data)
ggplot(data = earthquake_data, aes(x = 規模)) +
geom_bar(fill = "lightblue", colour = "black")
ggplot(data = dat, aes(x = dat$magnitude)) +
geom_bar(fill = "lightblue", colour = "black")
ggplot(data = dat, aes(x = dat$magnitude),xlab("magnitude")) +
geom_bar(fill = "lightblue", colour = "black")
ggplot(data = dat, aes(x = dat$magnitude),xlab="magnitude") +
geom_bar(fill = "lightblue", colour = "black")
xlab("XDD")
P2 <- ggplot(data = dat, aes(x = dat$magnitude)) +
geom_bar(fill = "lightblue", colour = "black")
P + xlab("XDD")
P2 + xlab("XDD")
P2 + xlab("magnitude")
P1 <- ggmap(map, darken = c(0.5, "white")) + geom_point(aes(x = lon, y = lat),size=2,
color = 'dark blue',data = dat)
dat <- read.csv("Earthquake_data.csv")
# February earthquake data imaging
# Using ggmap to visualize earthquake occurence
library(ggmap)
lon <- sapply((strsplit(as.character(dat$Longitude), ",")), as.numeric)
lat <- sapply((strsplit(as.character(dat$Latitude), ",")), as.numeric)
map <- get_map(location = 'Taiwan', zoom = 7, maptype = "terrain")
P1 <- ggmap(map, darken = c(0.5, "white")) + geom_point(aes(x = lon, y = lat),size=2,
color = 'dark blue',data = dat)
#
ggmap(map, darken = c(0.5, "white")) + geom_point(aes(x = lon, y = lat),size=2,
color = 'dark blue',data = dat)
map <- get_map(location = 'Taiwan', zoom = 7, maptype = "terrain")
ggmap(map, darken = c(0.5, "white")) + geom_point(aes(x = lon, y = lat),size=2,
color = 'dark blue',data = dat)
P1 <- ggmap(map, darken = c(0.5, "white")) + geom_point(aes(x = lon, y = lat),size=2,
color = 'dark blue',data = dat)
View(P1)
dat <- read.csv("Earthquake_data.csv")
# Using ggmap to visualize earthquake occurence
library(ggmap)
lon <- sapply((strsplit(as.character(dat$Longitude), ",")), as.numeric)
lat <- sapply((strsplit(as.character(dat$Latitude), ",")), as.numeric)
map <- get_map(location = 'Taiwan', zoom = 7, maptype = "terrain")
P1 <- ggmap(map, darken = c(0.5, "white")) + geom_point(aes(x = lon, y = lat),size=2,
color = 'dark blue',data = dat)
P2 <- ggplot(data = dat, aes(x = dat$magnitude)) +
geom_bar(fill = "lightblue", colour = "black")
P2 + xlab("magnitude")
View(p1)
View(P1)
P2 + xlab("magnitude")
plot(P1)
plot(p2)
plot(P2)
P3 <- ggplot(data = dat, aes(x = dat$depth)) +
geom_bar(fill = "lightblue", colour = "black")
P3 + xlab("depth")
install.packages("rmarkdown")
install.packages("knitr")
p4 <- qplot(data= dat, x=dat$magnitude, y=dat$depth, xlab='magnitude',ylab='depth')
library(ggplot2)
p4 <- qplot(data= dat, x=dat$magnitude, y=dat$depth, xlab='magnitude',ylab='depth')
plot(p4)
knitr::opts_chunk$set(echo = TRUE)
P4 <- qplot(data= dat, x=dat$magnitude, y=dat$depth, xlab='magnitude',ylab='depth',geom = c("point", "smooth"))
plot(P4)
