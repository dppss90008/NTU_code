all$SibSp[550] <- 0
all$Parch[1222] <- 1
all$Fsize[c(550, 1222)] <- 2
kable(all[all$FsizeName=='2Davies',c(2,3,14,5,6,7,8,17,9,15)])
###Families; what about uncles, aunts, cousins, nieces, grandparents, brothers/sisters-in law?
kable(all[all$Ticket %in% c('29104', '29105', '29106'),c(2,3,4,5,6,7,8,9,15)])
NC <- all[all$FsizeName %in% SizeCheck$FsizeName,] #create data frame with only relevant Fsizenames
#extracting maiden names
NC$Name <- sub("\\s$", "", NC$Name) #removing spaces at end Name
NC$Maiden <- sub(".*[^\\)]$", "", NC$Name) #remove when not ending with ')'
NC$Maiden <- sub(".*\\s(.*)\\)$", "\\1", NC$Maiden)
NC$Maiden[NC$Title!='Mrs'] <- "" #cleaning up other stuff between brackets (including Nickname of a Mr)
NC$Maiden <- sub("^\\(", '', NC$Maiden) #removing opening brackets (sometimes single name, no spaces between brackets)
#making an exceptions match
NC$Maiden[NC$Name=='Andersen-Jensen, Miss. Carla Christine Nielsine'] <- 'Jensen'
#take only Maiden names that also exist as surname in other Observations
NC$Maiden2[NC$Maiden %in% NC$Surname] <- NC$Maiden[NC$Maiden %in% NC$Surname]
#create surname+maiden name combinations
NC$Combi[!is.na(NC$Maiden2)] <- paste(NC$Surname[!is.na(NC$Maiden2)], NC$Maiden[!is.na(NC$Maiden2)])
#create labels dataframe with surname and maiden merged into one column
labels1 <- NC[!is.na(NC$Combi), c('Surname','Combi')]
labels2 <- NC[!is.na(NC$Combi), c('Maiden','Combi')]
colnames(labels2) <- c('Surname', 'Combi')
labels1 <- rbind(labels1, labels2)
NC$Combi <- NULL
NC <- left_join(NC, labels1, by='Surname')
#Find the maximum Fsize within each newly found 'second degree' family
CombiMaxF <- NC[!is.na(NC$Combi),] %>%
group_by(Combi) %>%
summarise(MaxF=max(Fsize)) #summarise(MaxF=n())
NC <- left_join(NC, CombiMaxF, by = "Combi")
#create family names for those larger families
NC$FsizeCombi[!is.na(NC$Combi)] <- paste(as.character(NC$Fsize[!is.na(NC$Combi)]), NC$Combi[!is.na(NC$Combi)], sep="")
#find the ones in which not all Fsizes are the same
FamMaid <- NC[!is.na(NC$FsizeCombi),] %>%
group_by(FsizeCombi, MaxF, Fsize) %>%
summarise(NumObs=n())
FamMaidWrong <- FamMaid[FamMaid$MaxF!=FamMaid$NumObs,]
kable(unique(NC[!is.na(NC$Combi) & NC$FsizeCombi %in% FamMaidWrong$FsizeCombi, c('Combi', 'MaxF')]))
NC$MaxF <- NULL #erasing MaxF column maiden combi's
#Find the maximum Fsize within remaining families (no maiden combi's)
FamMale <- NC[is.na(NC$Combi),] %>%
group_by(Surname) %>%
summarise(MaxF=max(Fsize))
NC <- left_join(NC, FamMale, by = "Surname")
NCMale <- NC[is.na(NC$Combi),] %>%
group_by(Surname, FsizeName, MaxF) %>%
summarise(count=n()) %>%
group_by(Surname, MaxF) %>%
filter(n()>1) %>%
summarise(NumFsizes=n())
NC$Combi[NC$Surname %in% NCMale$Surname] <- NC$Surname[NC$Surname %in% NCMale$Surname]
kable(NCMale[, c(1,2)])
kable(all[all$Surname=='Vander Planke', c(2,3,4,5,6,7,8,9,15)])
```
This means that altogether, there are 9 families (37 passengers) that include 'second degree' family members. What I want to do is give each member in such family the same Fsize (which gives everybody in these families the same survival chances with regards to the group variable). I have chosen to make this the average of the Fsize (which are based on siblings/spouse/parents/children only).
```{r}
#selecting those 37 passengers In Not Correct dataframe
NC <- NC[(NC$FsizeCombi %in% FamMaidWrong$FsizeCombi)|(NC$Surname %in% NCMale$Surname),]
#calculating the average Fsize for those 9 families
NC1 <- NC %>%
group_by(Combi) %>%
summarise(Favg=mean(Fsize))
kable(NC1)
```
A result is that for instance the Fsize is 4 for all 6 people in the Richards-Hockings family. This exactly what I wanted, as I wanted to combine those people into a group with all members having the same Fsize (to give equal survival chances to all members within the group) but also not the maximum size as they are less likely to stay together than first degree families.
```{r}
NC <- left_join(NC, NC1, by = "Combi") #adding Favg to NC dataframe
NC$Favg <- round(NC$Favg) #rounding those averages to integers
NC <- NC[, c('PassengerId', 'Favg')]
all <- left_join(all, NC, by='PassengerId')
#replacing Fsize by Favg
all$Fsize[!is.na(all$Favg)] <- all$Favg[!is.na(all$Favg)]
```
###Can we still find more second degree families?
Am I still missing some second degree families? Yes, at it appears that some people traveling solo with the same surname have tickets with almost the same number!
```{r}
#creating a variable with almost the same ticket numbers (only last 2 digits varying)
all$Ticket2 <- sub("..$", "xx", all$Ticket)
```
As they have no sibling/spouses and no parents/children, these people are likely cousins/uncles. If you look deeper into the data, you will see that these groups of cousins/uncles sometimes also travel with (first degree) families. However, I think the key to this exercise is not to find the absolute largest groups that people may have stayed together with. I think it should be to detect smaller groups that actually stayed together. It sounds reasonable to assume that first degree families stayed together, and that uncles/cousins also took care of each other (this is consistent with the averaging of the Fsizes in the previous section). Altogether, I have found another 56 passengers that I can assign a group size to.
```{r}
rest <- all %>%
select(PassengerId, Title, Age, Ticket, Ticket2, Surname, Fsize) %>%
filter(Fsize=='1') %>%
group_by(Ticket2, Surname) %>%
summarise(count=n())
rest <- rest[rest$count>1,]
rest1 <- all[(all$Ticket2 %in% rest$Ticket2 & all$Surname %in% rest$Surname & all$Fsize=='1'), c('PassengerId', 'Surname', 'Title', 'Age', 'Ticket', 'Ticket2', 'Fsize', 'SibSp', 'Parch')]
rest1 <- left_join(rest1, rest, by = c("Surname", "Ticket2"))
rest1 <- rest1[!is.na(rest1$count),]
rest1 <- rest1 %>%
arrange(Surname, Ticket2)
kable(rest1[1:12,])
```
```{r}
#replacing Fsize size in my overall dataframe with the count numbers in the table above
all <- left_join(all, rest1)
for (i in 1:nrow(all)){
if (!is.na(all$count[i])){
all$Fsize[i] <- all$count[i]
}
}
```
###Did people book together?
Besides families, groups of friends can off course also travel together. A nice example of this is the ticket below.
```{r}
kable(all[all$Ticket=='1601', c('Survived', 'Pclass', 'Title', 'Surname', 'Age', 'Ticket', 'SibSp', 'Parch', 'Fsize')])
```
Below, I am adding the number of people on each ticket as variable.
```{r}
#composing data frame with group size for each Ticket
TicketGroup <- all %>%
select(Ticket) %>%
group_by(Ticket) %>%
summarise(Tsize=n())
all <- left_join(all, TicketGroup, by = "Ticket")
```
Very similarly to the family group sizes, small groups of 2-4 people traveling together on the same ticket have a higher chance of survival.
```{r}
ggplot(all[!is.na(all$Survived),], aes(x = Tsize, fill = Survived)) +
geom_bar(stat='count', position='dodge') +
scale_x_continuous(breaks=c(1:11)) +
labs(x = 'Ticket Size') + theme_grey()
```
As there is so much overlap between family size and ticket size, I am consolidating these two variables into one group variable. Now I can finally created my factorized variable for the group sizes.
```{r}
#taking the max of family and ticket size as the group size
all$Group <- all$Fsize
for (i in 1:nrow(all)){
all$Group[i] <- max(all$Group[i], all$Tsize[i])
}
#Creating final group categories
all$GroupSize[all$Group==1] <- 'solo'
all$GroupSize[all$Group==2] <- 'duo'
all$GroupSize[all$Group>=3 & all$Group<=4] <- 'group'
all$GroupSize[all$Group>=5] <- 'large group'
all$GroupSize <- as.factor(all$GroupSize)
```
As '1' and '2' are large groups with their own typical survival rates, I am keeping them as separate groups. Sizes '3' and '4' clearly have the best survival chances, and the groups of 5 and more clearly have worse chances.
```{r}
g1 <- ggplot(all[!is.na(all$Survived),], aes(x = Group, fill = Survived)) +
geom_bar(stat='count', position='dodge') +
scale_x_continuous(breaks=c(1:11)) +
labs(x = 'Final Group Sizes') + theme_grey()
g2 <- ggplot(all[!is.na(all$Survived),], aes(x = GroupSize, fill = Survived)) +
geom_bar(stat='count', position='dodge') +
labs(x = 'Final Group Categories') + theme_grey() +
scale_x_discrete (limits = c('solo', 'duo', 'group', 'large group'))
grid.arrange(g2, g1)
```
```{r, echo=FALSE}
#clean up
all$count <- NULL
all$Name <- NULL
rm(CombiMaxF)
rm(FamMaid)
rm(FamMaidWrong)
rm(FamMale)
rm(labels1)
rm(labels2)
rm(NC)
rm(NC1)
rm(NCMale)
rm(rest)
#rm(rest1)
rm(SizeCheck)
rm(TicketGroup)
rm(p1); rm(p2); rm(p3); rm(p4); rm(p5); rm(p6)
```
kable(all[which(is.na(all$Embarked)),c('Surname', 'Title', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Group') ])
all$FarePP <- all$Fare/all$Tsize #creating the Fare Per Person variable
tab2 <- all[(!is.na(all$Embarked) & !is.na(all$Fare)),] %>%
group_by(Embarked, Pclass) %>%
summarise(FarePP=median(FarePP))
kable(tab2)
```
As the FarePP of those two women is 40, they most likely embarked at Cherbourgh.
```{r}
#imputing missing Embarked values
all$Embarked[all$Ticket=='113572'] <- 'C'
#converting Embarked into a factor
all$Embarked <- as.factor(all$Embarked)
```
I can actually use the same table to find a sensible fare for Mr Story. As you can see below, he traveled 3rd class and embarked at Southampton.
```{r}
#display passengers with missing Fare
kable(all[which(is.na(all$Fare)), c('Surname', 'Title', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Group')])
```
```{r}
#imputing FarePP (as the Fare will be dropped later on anyway)
all$FarePP[1044] <- 7.8
```
###The Fare Per Person Variable
Although there now are no missing FarePP's anymore, I also noticed that 17 Fares actually have the value 0. These people are not children that might have traveled for free. I think the information might actually be correct (have people won free tickets?), but I also think that the zero-Fares might confuse the algorithm. For instance, there are zero-Fares within the 1st class passengers. To avoid this possible confusion, I am replacing these values by the median FarePP's for each Pclass.
```{r}
tab3 <- all[(!is.na(all$FarePP)),] %>%
group_by(Pclass) %>%
summarise(MedianFarePP=median(FarePP))
all <- left_join(all, tab3, by = "Pclass")
all$FarePP[which(all$FarePP==0)] <- all$MedianFarePP[which(all$FarePP==0)]
```
Below you can see that the FarePP is very skewed. I know that this is not desirable for some algorithms, and can be solved by taking the logarithm or normalisation (preprocessing with centering and scaling).
```{r}
ggplot(all, aes(x=FarePP)) +
geom_histogram(binwidth = 5, fill='blue') + theme_grey() +
scale_x_continuous(breaks= seq(0, 150, by=10))
```
Another option is to use Fare Bins instead of keeping the FarePP as a numeric variable. I am using Fare Bin in the GBM model. As there are more FareBins than Pclasses, there is of course some overlap between FareBins and Pclasses.
```{r}
#Note Hmisc needs to be loaded before dplyr, as the other way around errors occured due to the kernel using the Hmisc summarize function instead of the dplyr summarize function
all$FareBins <- cut2(all$FarePP, g=5)
ggplot(all[!is.na(all$Survived),], aes(x=FareBins, fill=Survived))+
geom_bar(stat='count') + theme_grey() + facet_grid(.~Pclass)+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
##Predicting missing Age values
The density plot below shows that survival chances of children are relatively high. Survival chances of ages 20-30 are below average, and I see less significant differences in the 30+ region. I think there may be a lot of solo travelers in the 20-30 category, which could explain the below averages survival chances. A possible use case of Age could be to use it to identify children. Therefore, I will focus on good looking Age imputations in the region 0-18 years old.
```{r}
ggplot(all[(!is.na(all$Survived) & !is.na(all$Age)),], aes(x = Age, fill = Survived)) +
geom_density(alpha=0.5, aes(fill=factor(Survived))) + labs(title="Survival density and Age") +
scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) + theme_grey()
```
I first want to visualize the relation between the Age. Title and Pclass seem the most important predictors for Age to me. As you can see below, there are significant differences in Age across the Titles (By the way, this graph tells me that "Masters" are all very young. I did not know what a master was, but googling it tells me that a master was used as a title for the eldest son only.). Similarly, there differences in Age when looking at the Title/Passenger Class combinations.
```{r}
ggplot(all[!is.na(all$Age),], aes(x = Title, y = Age, fill=Pclass )) +
geom_boxplot() + scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) + theme_grey()
```
The title Master seems to be a good predictor for male children. However, female children are included in the Miss title, and of the 263 missing age values, 51 are Misses. If I would just take the median Age of the Titles (possibly also by Pclass), I would at least not predict the missing ages of female children well. I tried both Mice imputation and Linear Regression, and focused on how good the imputations for children looked. The Mice imputations looked reasonable, but I preferred Linear Regression.
```{r}
#predicting Age with Linear Regression
set.seed(12000)
AgeLM <- lm(Age ~ Pclass + Sex + SibSp + Parch + Embarked + Title + GroupSize, data=all[!is.na(all$Age),])
summary(AgeLM)
all$AgeLM <- predict(AgeLM, all)
```
par(mfrow=c(1,2))
hist(all$Age[!is.na(all$Age)], main='Original data, non-missing', xlab='Age', col='green')
hist(all$AgeLM[is.na(all$Age)], main= 'LM NA predictions', xlab='Age', col='orange', xlim=range(0:80))
all[(is.na(all$Age) & all$AgeLM <18), c('Sex', 'SibSp', 'Parch', 'Title', 'Pclass', 'Survived', 'AgeLM')]
indexMissingAge <- which(is.na(all$Age))
indexAgeSurvivedNotNA<- which(!is.na(all$Age) & (!is.na(all$Survived))) #needed in sections 4.6 and 4.7
all$Age[indexMissingAge] <- all$AgeLM[indexMissingAge]
View(all)
all$Cabin[is.na(all$Cabin)] <- "U"
all$Cabin <- substring(all$Cabin, 1, 1)
all$Cabin <- as.factor(all$Cabin)
ggplot(all[(!is.na(all$Survived)& all$Cabin!='U'),], aes(x=Cabin, fill=Survived)) +
geom_bar(stat='count') + theme_grey() + facet_grid(.~Pclass) + labs(title="Survivor split by class and Cabin")
c1 <- round(prop.table(table(all$Survived[(!is.na(all$Survived)&all$Cabin!='U')], all$Cabin[(!is.na(all$Survived)&all$Cabin!='U')]),2)*100)
kable(c1)
ggplot(all[all$Age<14.5 & !is.na(all$Survived),], aes(x=Pclass, fill=Survived))+
geom_bar(stat='count') + theme_grey(base_size = 18)
all$IsChildP12 <- 'No'
all$IsChildP12[all$Age<=14.5 & all$Pclass %in% c('1', '2')] <- 'Yes'
all$IsChildP12 <- as.factor(all$IsChildP12)
d1 <- ggplot(all[!is.na(all$Survived),], aes(x = Embarked, fill = Survived)) +
geom_bar(stat='count') + theme_grey() + labs(x = 'Embarked', y= 'Count')
d2 <- ggplot(all[!is.na(all$Survived),], aes(x = Embarked, fill = Survived)) +
geom_bar(stat='count', position= 'fill') + theme_grey() + labs(x = 'Embarked', y= 'Percent')
grid.arrange(d1, d2, nrow=1)
ggplot(all[indexAgeSurvivedNotNA,], aes(x = Age, fill = Survived)) +
geom_histogram(aes(fill=factor(Survived))) + labs(title="Survival density, known-ages, and Embarked") +
scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) + theme_grey() + facet_grid(.~Embarked)
tab1 <- rbind(table(all$Embarked[!is.na(all$Survived)]),table(all$Embarked[indexAgeSurvivedNotNA]))
tab1 <- cbind(tab1, (rowSums(tab1)))
tab1 <- rbind(tab1, tab1[1,]-tab1[2,])
tab1 <- rbind(tab1, round((tab1[3,]/tab1[1,])*100))
rownames(tab1) <- c("All", "With Age", "Missing Age", "Percent Missing")
colnames(tab1) <- c("C", "Q", "S", "Total")
kable(tab1)
TicketSurvivors <- all %>%
group_by(Ticket) %>%
summarize(Tsize = length(Survived),
NumNA = sum(is.na(Survived)),
SumSurvived = sum(as.numeric(Survived)-1, na.rm=T))
all <- left_join(all, TicketSurvivors)
all$AnySurvivors[all$Tsize==1] <- 'other'
all$AnySurvivors[all$Tsize>=2] <- ifelse(all$SumSurvived[all$Tsize>=2]>=1, 'survivors in group', 'other')
all$AnySurvivors <- as.factor(all$AnySurvivors)
kable(x=table(all$AnySurvivors), col.names= c('AnySurvivors', 'Frequency'))
all$IsSolo[all$SibSp==0] <- 'Yes'
all$IsSolo[all$SibSp!=0] <- 'No'
all$IsSolo <- as.factor(all$IsSolo)
ggplot(all[!is.na(all$Survived),], aes(x = IsSolo, fill = Survived)) +
geom_bar(stat='count') + theme_grey(base_size = 18)
all$PassengerId <- NULL
all$SibSp <- NULL
all$Parch <- NULL
all$Ticket <- NULL
all$Fare <- NULL
all$Cabin <- NULL
all$Surname <- NULL
all$Fsize <- NULL
all$FsizeName <- NULL
all$Favg <- NULL
all$Tsize <- NULL
#all$Group <- NULL
all$Ticket2 <- NULL
all$AgeLM <- NULL
all$Child <- NULL
all$HasParch <- NULL
all$MedianFarePP <- NULL
rm(tab1); rm(tab2); rm(tab3); rm(AgeLM); rm(c1); rm(d1); rm(d2);
View(all)
trainClean <- all[!is.na(all$Survived),]
testClean <- all[is.na(all$Survived),]
View(trainClean)
set.seed(2017)
caret_matrix <- train(x=trainClean[,c('PclassSex', 'GroupSize', 'FarePP', 'AnySurvivors', 'IsChildP12')], y=trainClean$Survived, data=trainClean, method='rf', trControl=trainControl(method="cv", number=5))
As mentioned before, I especially looked at young predicted ages. Both mice and Linear Regression predicted all Masters with missing ages to be children indeed (the one in Linear Regression with a negative age did not bother me that much, as it is categorized as a child anyway). Mice predicted some Mr.'s to be 14 years old, which is too young. As Linear Regression also predicted a reasonable number of Misses to be children, I eventually chose Linear Regression.
#display which passengers are predicted to be children (age<18) with Linear Regression.
all[(is.na(all$Age) & all$AgeLM <18), c('Sex', 'SibSp', 'Parch', 'Title', 'Pclass', 'Survived', 'AgeLM')]
#imputing Linear Regression predictions for missing Ages
indexMissingAge <- which(is.na(all$Age))
indexAgeSurvivedNotNA<- which(!is.na(all$Age) & (!is.na(all$Survived))) #needed in sections 4.6 and 4.7
all$Age[indexMissingAge] <- all$AgeLM[indexMissingAge]
```
So now all missing data have been imputed. Am I going to use Age as a predictor in my model? I am not sure yet, as the substantial number of imputations will also add noise. I wil look at using it to create a Child predictor later on.
##What to do with Cabin?
Cabin is very sparsely populated. So I either have to ignore it, or use it somehow without making it too specific. On the internet, you can find that that the first letter corresponds to the Deck. Decks A-E are the topdecks and cabins on those decks are mostly first class.
```{r}
#replacing NAs with imaginary Deck U, and keeping only the first letter of ech Cabin (=Deck)
all$Cabin[is.na(all$Cabin)] <- "U"
all$Cabin <- substring(all$Cabin, 1, 1)
all$Cabin <- as.factor(all$Cabin)
ggplot(all[(!is.na(all$Survived)& all$Cabin!='U'),], aes(x=Cabin, fill=Survived)) +
geom_bar(stat='count') + theme_grey() + facet_grid(.~Pclass) + labs(title="Survivor split by class and Cabin")
```
Below, you can see that there are interesting difference among Decks. For instance, the top Deck (A) was not best place to be. Even Deck F had better survival rates.
```{r}
c1 <- round(prop.table(table(all$Survived[(!is.na(all$Survived)&all$Cabin!='U')], all$Cabin[(!is.na(all$Survived)&all$Cabin!='U')]),2)*100)
kable(c1)
```
Although I feel that Deck and Deck sections (front/back of boat, sections close to stairs et cetera) would be great predictors, I am not using Cabin due to the the sparseness of the data.
##How to deal with Children in the model?
The survival density plot in the Age section shows that Children below roughly 14.5 (which is also the maximum Age of Masters in the data) have a better survival rate than then other Ages. However, if you look at the imputed Ages below 14.5, you will also see that all these age imputation are for Pclass 3 and most of these children actually died (10 out of 13).
This makes me wonder if I should add a survival 'bonus' for all Pclasses. Below you can see that most children in P3 actually die. As these children in P3 also include age imputations which may add noise, I decided to exclude P3 from the Child predictor.
```{r, out.width="50%"}
ggplot(all[all$Age<14.5 & !is.na(all$Survived),], aes(x=Pclass, fill=Survived))+
geom_bar(stat='count') + theme_grey(base_size = 18)
```
```{r}
all$IsChildP12 <- 'No'
all$IsChildP12[all$Age<=14.5 & all$Pclass %in% c('1', '2')] <- 'Yes'
all$IsChildP12 <- as.factor(all$IsChildP12)
```
##What does Embarked tell us?
Although I feel that the city of Embarked should not be related to survival rates, I still wanted to check it. As you can see below, there somehow are significant differences between the three ports of embarkment.
```{r}
d1 <- ggplot(all[!is.na(all$Survived),], aes(x = Embarked, fill = Survived)) +
geom_bar(stat='count') + theme_grey() + labs(x = 'Embarked', y= 'Count')
d2 <- ggplot(all[!is.na(all$Survived),], aes(x = Embarked, fill = Survived)) +
geom_bar(stat='count', position= 'fill') + theme_grey() + labs(x = 'Embarked', y= 'Percent')
grid.arrange(d1, d2, nrow=1)
```
ggplot(all[indexAgeSurvivedNotNA,], aes(x = Age, fill = Survived)) +
geom_histogram(aes(fill=factor(Survived))) + labs(title="Survival density, known-ages, and Embarked") +
scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) + theme_grey() + facet_grid(.~Embarked)
```
This shows that is very little data for especially Queenstown when looking at known Ages. Below you can see that the total number of people who embarked at Queenstown is low indeed, but especially the high percentage of missing ages in Queenstown is really high. Using imputed ages will therefore add too much noise, and combining Age and Embarked as a predictor is a bad idea.
```{r}
tab1 <- rbind(table(all$Embarked[!is.na(all$Survived)]),table(all$Embarked[indexAgeSurvivedNotNA]))
tab1 <- cbind(tab1, (rowSums(tab1)))
tab1 <- rbind(tab1, tab1[1,]-tab1[2,])
tab1 <- rbind(tab1, round((tab1[3,]/tab1[1,])*100))
rownames(tab1) <- c("All", "With Age", "Missing Age", "Percent Missing")
colnames(tab1) <- c("C", "Q", "S", "Total")
kable(tab1)
```
The only other thing that I can think of that might explain the differences is that probably people from the different embarkement cities are somehow grouped on certain sections of the decks.
I kept Embarked in my model in early versions. However, it gradually became clear that Embarked does not add anything and I am not using it anymore.
##Ticket survivors
This variable checks if any people in a group survived. The idea is that if anyone in a certain group survived, chances of others also surviving are higher. I did this using the Ticket information, and it improved the scores.
```{r}
TicketSurvivors <- all %>%
group_by(Ticket) %>%
summarize(Tsize = length(Survived),
NumNA = sum(is.na(Survived)),
SumSurvived = sum(as.numeric(Survived)-1, na.rm=T))
```
```{r}
all <- left_join(all, TicketSurvivors)
all$AnySurvivors[all$Tsize==1] <- 'other'
all$AnySurvivors[all$Tsize>=2] <- ifelse(all$SumSurvived[all$Tsize>=2]>=1, 'survivors in group', 'other')
all$AnySurvivors <- as.factor(all$AnySurvivors)
kable(x=table(all$AnySurvivors), col.names= c('AnySurvivors', 'Frequency'))
```
##Adding an "Is Solo" variable" based on Siblings and Spouse (SibSp) only
In an earlier version, I experimented with an "IsSolo" predictor that was based on the Group size. However, this double counted the Group categories too much and did not work. Eventually, I added an IsSolo predictor that is only based on the SibSp information. Using this predictor in the SVM model leads to slightly better results.
```{r, out.width="50%"}
all$IsSolo[all$SibSp==0] <- 'Yes'
all$IsSolo[all$SibSp!=0] <- 'No'
all$IsSolo <- as.factor(all$IsSolo)
ggplot(all[!is.na(all$Survived),], aes(x = IsSolo, fill = Survived)) +
geom_bar(stat='count') + theme_grey(base_size = 18)
```
#Predictions (with caret cross validation)
```{r, echo=FALSE}
#cleaning up
all$PassengerId <- NULL
all$SibSp <- NULL
all$Parch <- NULL
all$Ticket <- NULL
all$Fare <- NULL
all$Cabin <- NULL
all$Surname <- NULL
all$Fsize <- NULL
all$FsizeName <- NULL
all$Favg <- NULL
all$Tsize <- NULL
#all$Group <- NULL
all$Ticket2 <- NULL
all$AgeLM <- NULL
all$Child <- NULL
all$HasParch <- NULL
all$MedianFarePP <- NULL
rm(tab1); rm(tab2); rm(tab3); rm(AgeLM); rm(c1); rm(d1); rm(d2);
```
Altogether, I created predictions with 3 different algorithms. In addition, I tried to combine (ensemble) the models in 3 different ways. This ensemble further improved the scores.
```{r}
#splitting data into train and test set again
trainClean <- all[!is.na(all$Survived),]
testClean <- all[is.na(all$Survived),]
```
##Random Forest model
I started this analysis with just a Random Forest model, as it is known for high accuracy and limiting overfitting.
Although the formula function must be used with many algorithms, it is better to not use it with Random Forest as this causes issues with weights of predictors. I am just using 5 predictors.
```{r}
library(e1071)
set.seed(2017)
caret_matrix <- train(x=trainClean[,c('PclassSex', 'GroupSize', 'FarePP', 'AnySurvivors', 'IsChildP12')], y=trainClean$Survived, data=trainClean, method='rf', trControl=trainControl(method="cv", number=5))
caret_matrix
caret_matrix$results
```
```{r}
#extracting variable importance and make graph with ggplot (looks nicer that the standard varImpPlot)
rf_imp <- varImp(caret_matrix, scale = FALSE)
rf_imp <- rf_imp$importance
rf_gini <- data.frame(Variables = row.names(rf_imp), MeanDecreaseGini = rf_imp$Overall)
ggplot(rf_gini, aes(x=reorder(Variables, MeanDecreaseGini), y=MeanDecreaseGini, fill=MeanDecreaseGini)) +
geom_bar(stat='identity') + coord_flip() + theme(legend.position="none") + labs(x="") +
ggtitle('Variable Importance Random Forest') + theme(plot.title = element_text(hjust = 0.5))
```
```{r}
#using the model to make Survival predictions on the test set
solution_rf <- predict(caret_matrix, testClean)
```
##Support Vector Machine (SVM) model
The second algorithm that I want to use is SVM, as it is known to work well with small datasets. As I am only having a few predictors and relatively many observation, I am choosing svmRadial (Gaussian) over svmLinear.
```{r}
set.seed(2017)
caret_svm <- train(Survived~ PclassSex + FarePP + AnySurvivors + IsChildP12 + IsSolo, data=trainClean, method='svmRadial', preProcess= c('center', 'scale'), trControl=trainControl(method="cv", number=5))
library(randomForest)
library(e1071)
install.packages("e1071")
library(e1071)
# Read the titanicTrain data and store it in titanic
titanic <- read.csv("titanicTrain.csv")
setwd("E:/GitHub/NTU_code/week_8/task_8")
# Read the titanicTrain data and store it in titanic
train <- read.csv("titanicTrain.csv")
train <- titanic[c(1:1000),]
# Read the titanicTrain data and store it in titanic
train <- read.csv("titanicTrain.csv")
train <- train[c(1:1000),]
sapply(titanic, function(x) {sum(is.na(x))})
train <- read.csv("titanicTrain.csv", stringsAsFactors = F, na.strings = c("NA", ""))
train <- train[c(1:1000),]
test <- read.csv("titanicQuestion.csv", stringsAsFactors = F, na.strings = c("NA", ""))
all <- rbind(train,test)
# Train data 上面的NA
str(titanic)
# Train data 上面的NA
str(all)
sapply(titanic, function(x) {sum(is.na(x))})
sapply(all, function(x) {sum(is.na(x))})
# 篩選登船與沒有登船存活率
boat <- all[all$boat!='',]
View(all)
# 篩選登船與沒有登船存活率
boat <- train[train$boat!='',]
# 篩選登船與沒有登船存活率
boat <- train[train$boat!='',]
boat <- summary(as.factor(boat$survived))
boat
View(train)
train <- read.csv("titanicTrain.csv")
train <- train[c(1:1000),]
test <- read.csv("titanicQuestion.csv")
all <- rbind(train,test)
# Train data 上面的NA
str(all)
sapply(all, function(x) {sum(is.na(x))})
# 篩選登船與沒有登船存活率
boat <- train[train$boat!='',]
View(boat)
# 篩選登船與沒有登船存活率
boat <- train[train$boat!='',] %>% summary
# 篩選登船與沒有登船存活率
boat <- train[train$boat!='',] %>% as.factor()
# 篩選男女存活率
all$sex <- as.factor(all$sex)
all$sex
summary(all$sex))
summary(all$sex)
# 篩選男女存活率
all$sex <- as.factor(all$sex)
View(all)
View(test)
View(train)
View(test)
